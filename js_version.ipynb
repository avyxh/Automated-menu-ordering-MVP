{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ff648c-6187-4d68-a39c-7ef959a9acfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "import matplotlib.pyplot as plt\n",
       "import numpy as np\n",
       "import os\n",
       "import pandas as pd\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn import metrics\n",
       "from sklearn.ensemble import RandomForestClassifier\n",
       "from sklearn.feature_extraction.text import CountVectorizer\n",
       "from sklearn.feature_extraction.text import TfidfVectorizer\n",
       "from sklearn.linear_model import LogisticRegression\n",
       "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
       "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
       "from sklearn.naive_bayes import MultinomialNB\n",
       "\n",
       "def test(df):\n",
       "    X_train, X_test, y_train, y_test = train_test_split(\n",
       "        df['descriptor'], df['item'], shuffle=True, test_size=0.2, random_state=None)\n",
       "\n",
       "    tfidf = TfidfVectorizer(sublinear_tf=True,\n",
       "                            min_df=1,\n",
       "                            max_df=50,\n",
       "                            norm='l1',\n",
       "                            ngram_range=(1, 1),\n",
       "                            stop_words='english')\n",
       "\n",
       "    X_train_counts = tfidf.fit_transform(X_train)\n",
       "    X_test_counts = tfidf.transform(X_test)\n",
       "\n",
       "    model = MultinomialNB(alpha=1e-06)\n",
       "    model.fit(X_train_counts, y_train)\n",
       "\n",
       "    y_pred_prob = model.predict_proba(X_test_counts)\n",
       "    y_predict_0 = y_pred_prob[:, 0]\n",
       "    y_predict_1 = y_pred_prob[:, 1]\n",
       "    y_predict_2 = y_pred_prob[:, 2]\n",
       "    predicted = pd.DataFrame()\n",
       "    predicted[\"Chicken McNuggets\"] = y_predict_0\n",
       "    predicted[\"Iced Coffee\"] = y_predict_1\n",
       "    predicted[\"Quarter Pounder\"] = y_predict_2\n",
       "\n",
       "    y_pred = model.predict(X_test_counts)\n",
       "    acc = metrics.accuracy_score(y_test, y_pred)\n",
       "\n",
       "    return acc, tfidf, model\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter, defaultdict\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequencesw\n",
    "\n",
    "\n",
    "\n",
    "# tensorflow hub\n",
    "import tensorflow_hub as hub\n",
    "# tensor flow module\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# used to create word encoders\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from matplotlib import colors\n",
    "import nltk, keras, string, re, html, math\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df['descriptor'], df['item'], shuffle=True, test_size=0.2, random_state=None)\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True,\n",
    "                            min_df=1,\n",
    "                            max_df=50,\n",
    "                            norm='l1',\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words='english')\n",
    "\n",
    "X_train_counts = tfidf.fit_transform(X_train)\n",
    "X_test_counts = tfidf.transform(X_test)\n",
    "\n",
    "model = MultinomialNB(alpha=1e-06)\n",
    "model.fit(X_train_counts, y_train)\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_test_counts)\n",
    "y_predict_0 = y_pred_prob[:, 0]\n",
    "y_predict_1 = y_pred_prob[:, 1]\n",
    "y_predict_2 = y_pred_prob[:, 2]\n",
    "    predicted = pd.DataFrame()\n",
    "    predicted[\"Chicken McNuggets\"] = y_predict_0\n",
    "    predicted[\"Iced Coffee\"] = y_predict_1\n",
    "    predicted[\"Quarter Pounder\"] = y_predict_2\n",
    "\n",
    "    y_pred = model.predict(X_test_counts)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return acc, tfidf, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49a5dd36-24c0-4c0c-8991-1d8a19acda89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 1.0\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0941 - accuracy: 0.3802 - val_loss: 1.0702 - val_accuracy: 0.5833\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0575 - accuracy: 0.5990 - val_loss: 1.0456 - val_accuracy: 0.6458\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0187 - accuracy: 0.7708 - val_loss: 1.0130 - val_accuracy: 0.7500\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.9717 - accuracy: 0.8802 - val_loss: 0.9688 - val_accuracy: 0.7708\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.9096 - accuracy: 0.9271 - val_loss: 0.9095 - val_accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8290 - accuracy: 0.9479 - val_loss: 0.8337 - val_accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7266 - accuracy: 0.9792 - val_loss: 0.7334 - val_accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.9948 - val_loss: 0.6173 - val_accuracy: 0.9583\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.9948 - val_loss: 0.4930 - val_accuracy: 0.9583\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 1.0000 - val_loss: 0.3696 - val_accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 1.0000\n",
      "Neural Network Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"Vague_dataset.csv\")\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1['descriptor'], df1['item'], shuffle=True, test_size=0.2, random_state=None)\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=1, max_df=50, norm='l1', ngram_range=(1, 1), stop_words='english')\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "X_train_array = X_train_tfidf.toarray()\n",
    "X_test_array = X_test_tfidf.toarray()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "model = MultinomialNB(alpha=1e-06)\n",
    "model.fit(X_train_array, y_train_encoded)\n",
    "y_pred = model.predict(X_test_array)\n",
    "acc = metrics.accuracy_score(y_test_encoded, y_pred)\n",
    "\n",
    "print(f\"Naive Bayes Accuracy: {acc}\")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_array.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax') \n",
    "])\n",
    "\n",
    "opt = keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_array, tf.keras.utils.to_categorical(y_train_encoded, num_classes),\n",
    "          epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "X_test_tfidf_array = X_test_tfidf.toarray()\n",
    "loss, accuracy = model.evaluate(X_test_array, tf.keras.utils.to_categorical(y_test_encoded, num_classes))\n",
    "print(f\"Neural Network Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54bd18f-72af-432c-85e0-cb435943c915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29a496-007f-4416-8367-b05b5ae91441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
